{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import data_preprocessor as dp\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Load the dataset\n",
    "messy_data = pd.read_csv('../Data/messy_data.csv')\n",
    "clean_data = messy_data.copy()\n",
    "\n",
    "\n",
    "\n",
    "# 2. Preprocess the data\n",
    "clean_data = dp.impute_missing_values(clean_data, strategy='mean')\n",
    "clean_data = dp.remove_duplicates(clean_data)\n",
    "clean_data = dp.normalize_data(clean_data)\n",
    "clean_data = dp.remove_redundant_features(clean_data)\n",
    "\n",
    "# 3. Save the cleaned dataset\n",
    "clean_data.to_csv('../Data/clean_data.csv', index=False)\n",
    "\n",
    "\n",
    "#steps to ensure data and columns are ready for modelling \n",
    "target_column = clean_data.columns[0]\n",
    "if clean_data[target_column].dtype != 'object' and clean_data[target_column].dtype != 'category':\n",
    "    # If target is continuous, convert to binary or categorical labels (example)\n",
    "    threshold = clean_data[target_column].median()\n",
    "    clean_data[target_column] = (clean_data[target_column] > threshold).astype(int)  # Binary labels\n",
    "\n",
    "# 4. Train and evaluate the model\n",
    "dp.simple_model(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Messy Dataset Summary Statistics:\n",
      "           target            b            c            f            h  \\\n",
      "count  920.000000  1196.000000  1196.000000  1196.000000  1158.000000   \n",
      "mean     0.553261     0.004015    53.383779     0.001391   200.583765   \n",
      "std      0.497426     0.984837     9.534033     1.011656   110.061582   \n",
      "min      0.000000    -3.308750    28.000000    -2.820047     0.000000   \n",
      "25%      0.000000    -0.692960    47.000000    -0.633350   176.250000   \n",
      "50%      1.000000     0.004241    54.000000    -0.051965   224.000000   \n",
      "75%      1.000000     0.714572    60.000000     0.693539   270.000000   \n",
      "max      1.000000     2.982511    77.000000     3.323155   603.000000   \n",
      "\n",
      "                j            k            l            n            o  \\\n",
      "count  591.000000  1196.000000  1196.000000  1012.000000  1008.000000   \n",
      "mean    -0.600216     0.007269    -0.013268     4.904847   137.780754   \n",
      "std      1.067309     2.498874     0.958741     0.200283    26.175380   \n",
      "min     -5.954661   -24.268796    -2.802329     4.094345    60.000000   \n",
      "25%     -1.113061    -0.722036    -0.636907     4.787492   120.000000   \n",
      "50%     -0.324872     0.002258    -0.000074     4.941642   140.000000   \n",
      "75%      0.136188     0.699648     0.642745     5.062595   157.000000   \n",
      "max      1.369476    27.315031     3.328148     5.273000   202.000000   \n",
      "\n",
      "                 p            q            r            t            u  \\\n",
      "count  1122.000000  1009.000000  1196.000000  1110.000000  1079.000000   \n",
      "mean    137.660298   137.259233    53.376221     0.872252    53.328760   \n",
      "std      25.890960    25.790053     9.603964     1.077211     9.645423   \n",
      "min      60.522848    60.035804    27.548190    -2.600000    28.743286   \n",
      "25%     119.742012   119.041270    46.857255     0.000000    46.541317   \n",
      "50%     139.676137   139.602369    54.126896     0.500000    54.148423   \n",
      "75%     157.382495   156.970305    60.324072     1.500000    60.418600   \n",
      "max     200.680509   202.572685    77.484697     6.200000    78.520864   \n",
      "\n",
      "                 v            w           x            y           z  \n",
      "count  1116.000000  1079.000000  397.000000  1196.000000  598.000000  \n",
      "mean    132.247312     0.034028    0.667506    53.379991   -0.757779  \n",
      "std      18.872281     0.995701    0.924021     9.564497    1.257376  \n",
      "min       0.000000    -3.087673    0.000000    26.549257   -7.293222  \n",
      "25%     120.000000    -0.601836    0.000000    46.931375   -1.316941  \n",
      "50%     130.000000     0.035589    0.000000    54.448992   -0.439484  \n",
      "75%     140.000000     0.723486    1.000000    59.812460    0.094453  \n",
      "max     200.000000     3.933288    3.000000    79.712348    1.202416  \n"
     ]
    }
   ],
   "source": [
    "#Messy data summary stats\n",
    "\n",
    "print(\"Messy Dataset Summary Statistics:\")\n",
    "print(messy_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned Dataset Summary Statistics:\n",
      "           target           b           c           f           h           j  \\\n",
      "count  480.000000  480.000000  480.000000  480.000000  480.000000  480.000000   \n",
      "mean     0.418750    0.522296    0.546599    0.464234    0.356896    0.726543   \n",
      "std      0.493869    0.158945    0.184911    0.164020    0.163397    0.106851   \n",
      "min      0.000000    0.000000    0.020408    0.013818    0.000000    0.000000   \n",
      "25%      0.000000    0.415781    0.408163    0.357365    0.326700    0.731068   \n",
      "50%      0.000000    0.521850    0.571429    0.459911    0.388060    0.731068   \n",
      "75%      1.000000    0.628019    0.673469    0.581317    0.452736    0.735554   \n",
      "max      1.000000    1.000000    1.000000    0.904455    0.935323    0.983555   \n",
      "\n",
      "                k           l           n           t           v           w  \\\n",
      "count  480.000000  480.000000  480.000000  480.000000  480.000000  480.000000   \n",
      "mean     0.472264    0.447130    0.719951    0.413376    0.662055    0.443753   \n",
      "std      0.050411    0.158828    0.156547    0.124650    0.088057    0.129051   \n",
      "min      0.132092    0.000000    0.000000    0.181818    0.470000    0.000000   \n",
      "25%      0.456967    0.346269    0.622718    0.295455    0.600000    0.369781   \n",
      "50%      0.470013    0.448066    0.736857    0.386364    0.650000    0.444626   \n",
      "75%      0.483045    0.548913    0.842699    0.491477    0.700000    0.511252   \n",
      "max      0.900829    1.000000    1.000000    1.000000    1.000000    0.936428   \n",
      "\n",
      "                x           z  \n",
      "count  480.000000  480.000000  \n",
      "mean     0.221584    0.764771  \n",
      "std      0.275693    0.111160  \n",
      "min      0.000000    0.018779  \n",
      "25%      0.000000    0.769270  \n",
      "50%      0.222502    0.769270  \n",
      "75%      0.333333    0.790772  \n",
      "max      1.000000    1.000000  \n"
     ]
    }
   ],
   "source": [
    "#clean data summary stats \n",
    "print(\"\\nCleaned Dataset Summary Statistics:\")\n",
    "print(clean_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rows Removed: 716\n",
      "Columns Removed: 6\n"
     ]
    }
   ],
   "source": [
    "#analyze rows and columns that were removed \n",
    "\n",
    "rows_removed = messy_data.shape[0] - clean_data.shape[0]\n",
    "cols_removed = messy_data.shape[1] - clean_data.shape[1]\n",
    "print(f\"\\nRows Removed: {rows_removed}\")\n",
    "print(f\"Columns Removed: {cols_removed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data After Removing Redundant Features:\n",
      "   target               a         b         c                  d          e  \\\n",
      "0       0  lv hypertrophy  0.610389  0.714286       fixed defect  Cleveland   \n",
      "1       1  lv hypertrophy  0.358036  0.795918             normal  Cleveland   \n",
      "2       1  lv hypertrophy  0.595613  0.795918  reversable defect  Cleveland   \n",
      "3       0          normal  0.301262  0.183673             normal  Cleveland   \n",
      "4       0  lv hypertrophy  0.311787  0.265306             normal  Cleveland   \n",
      "\n",
      "          f                g         h      i  ...         l            m  \\\n",
      "0  0.505577   typical angina  0.386401   True  ...  0.319166  downsloping   \n",
      "1  0.729423     asymptomatic  0.474295  False  ...  0.412870         flat   \n",
      "2  0.409365     asymptomatic  0.379768  False  ...  0.124036         flat   \n",
      "3  0.603448      non-anginal  0.414594  False  ...  0.387424  downsloping   \n",
      "4  0.368214  atypical angina  0.338308  False  ...  0.411798    upsloping   \n",
      "\n",
      "          n       s         t      v         w         x        z      {  \n",
      "0  0.777404    Male  0.556818  0.725  0.296233  0.000000  0.76927  False  \n",
      "1  0.498693    Male  0.465909  0.800  0.453651  1.000000  0.76927   True  \n",
      "2  0.649442    Male  0.590909  0.600  0.444626  0.666667  0.76927   True  \n",
      "3  0.964459    Male  0.693182  0.650  0.255787  0.000000  0.76927  False  \n",
      "4  0.893518  Female  0.454545  0.650  0.523153  0.000000  0.76927  False  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "Number of features removed due to redundancy: 6\n"
     ]
    }
   ],
   "source": [
    "# 3. Calculate how many features were removed\n",
    "\n",
    "clean_data_before = messy_data.copy()\n",
    "dropped_features_count = len(clean_data_before.columns) - len(clean_data.columns)\n",
    "\n",
    "# 4. Print the cleaned data after removing redundant features\n",
    "print(\"\\nData After Removing Redundant Features:\")\n",
    "print(clean_data.head())\n",
    "\n",
    "# 5. Print how many features were removed due to redundancy\n",
    "print(f\"\\nNumber of features removed due to redundancy: {dropped_features_count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigscape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
